from nltk import word_tokenize


def to_tokens(text):
    return word_tokenize(text)
